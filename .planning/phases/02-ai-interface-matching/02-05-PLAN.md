---
phase: 02-ai-interface-matching
plan: 05
type: execute
wave: 3
depends_on:
  - "02-03"
  - "02-04"
files_modified:
  - src/lib/ai/command-handlers.ts
  - src/hooks/useChat.ts
  - src/components/chat/ChatInput.tsx
  - src/hooks/useVoiceInput.ts
  - src/hooks/useFileUpload.ts
  - src/components/chat/VoiceButton.tsx
  - src/components/chat/AttachmentButton.tsx
autonomous: false
requirements:
  - AIUI-05
  - AIUI-06

must_haves:
  truths:
    - "Matching requests in chat return ranked results"
    - "Voice input button transcribes Turkish speech"
    - "File attachments upload to Firebase Storage"
    - "Full conversation flow works end-to-end"
    - "User verification confirms all features work"
  artifacts:
    - path: "src/hooks/useVoiceInput.ts"
      provides: "Web Speech API wrapper for Turkish"
      exports: ["useVoiceInput"]
    - path: "src/hooks/useFileUpload.ts"
      provides: "Firebase Storage upload hook"
      exports: ["useFileUpload"]
  key_links:
    - from: "src/lib/ai/command-handlers.ts"
      to: "src/hooks/useMatching.ts"
      via: "matching integration"
      pattern: "findPropertiesForCustomer|findMatchesForCustomer"
---

<objective>
Complete integration of all Phase 2 features: wire matching to chat, add voice input, add file attachments, and verify everything works end-to-end.

Purpose: Final integration ensures all components work together seamlessly. Human verification confirms the AI interface meets user expectations.
Output: Fully functional AI chat interface with matching, voice, and attachments.
</objective>

<execution_context>
@/home/cagr/.claude/get-shit-done/workflows/execute-plan.md
@/home/cagr/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-ai-interface-matching/02-RESEARCH.md
@.planning/phases/02-ai-interface-matching/02-CONTEXT.md

# From previous plans
@src/lib/ai/command-handlers.ts
@src/hooks/useChat.ts
@src/hooks/useMatching.ts
@src/components/chat/ChatInput.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire Matching to Chat Command Handlers</name>
  <files>
    src/lib/ai/command-handlers.ts
    src/hooks/useChat.ts
  </files>
  <action>
**src/lib/ai/command-handlers.ts:**
Add matching handler:

```typescript
case 'request_matches':
  return handleMatchRequest(parsed.entities, context);

async function handleMatchRequest(
  entities: ParsedEntities,
  context: CommandContext
): Promise<CommandResult> {
  const { customerReference, propertyReference } = entities;

  // Find properties for customer
  if (customerReference) {
    // Search for customer by name
    const customers = await context.searchCustomers(customerReference);

    if (customers.length === 0) {
      return {
        message: `"${customerReference}" adında müşteri bulunamadı. Müşteri adını kontrol eder misin?`,
        needsInput: true
      };
    }

    if (customers.length > 1) {
      return {
        message: `${customers.length} müşteri buldum:\n${customers.map((c, i) =>
          `${i + 1}. ${c.name} (${c.preferences.budget.min}-${c.preferences.budget.max} TL)`
        ).join('\n')}\nHangisi için arayım?`,
        needsInput: true,
        options: customers.map(c => c.id)
      };
    }

    // Single customer found
    const customer = customers[0];
    const matches = await context.findPropertiesForCustomer(customer.id);

    if (matches.length === 0) {
      const noMatchExplanation = generateNoMatchExplanation(
        customer,
        context.properties
      );
      return {
        message: noMatchExplanation,
        embeddedMatches: []
      };
    }

    return {
      message: `${customer.name} için ${matches.length} mülk buldum:`,
      embeddedMatches: matches.map(m => ({
        propertyId: m.property.id,
        customerId: customer.id,
        score: m.score.score,
        explanation: m.explanation
      }))
    };
  }

  // Find customers for property
  if (propertyReference) {
    // Similar logic for reverse matching
  }

  return {
    message: 'Kimin için mülk aramamı istersin? Müşteri adını söyle.',
    needsInput: true
  };
}
```

**src/hooks/useChat.ts:**
Update to handle match results:

```typescript
// After getting result from handleCommand
if (result.embeddedMatches && result.embeddedMatches.length > 0) {
  addMessage({
    role: 'assistant',
    content: result.message,
    embeddedMatches: result.embeddedMatches
  });
} else {
  addMessage({
    role: 'assistant',
    content: result.message
  });
}
```

Ensure context includes matching functions:
```typescript
const context: CommandContext = {
  userId: user.uid,
  addProperty,
  updateProperty,
  addCustomer,
  searchProperties,
  searchCustomers,
  findPropertiesForCustomer,
  findCustomersForProperty,
  properties,
  customers
};
```
  </action>
  <verify>
- Type "Mehmet için mülk bul" in chat
- See match results with scores and explanations
- "Bu mülk için müşteri bul" returns customer matches
  </verify>
  <done>
- Matching integrated with chat commands
- Results render with MatchResults component
- Both directions work (customer -> properties, property -> customers)
  </done>
</task>

<task type="auto">
  <name>Task 2: Add Voice Input and File Attachments</name>
  <files>
    src/hooks/useVoiceInput.ts
    src/hooks/useFileUpload.ts
    src/components/chat/VoiceButton.tsx
    src/components/chat/AttachmentButton.tsx
    src/components/chat/ChatInput.tsx
  </files>
  <action>
**src/hooks/useVoiceInput.ts:**
Web Speech API wrapper per research:

```typescript
export function useVoiceInput(language = 'tr-TR') {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [isSupported, setIsSupported] = useState(false);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      setIsSupported(false);
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = language;
    recognition.continuous = false;
    recognition.interimResults = false;

    recognition.onresult = (event) => {
      const text = event.results[0][0].transcript;
      setTranscript(text);
      setIsListening(false);
    };

    recognition.onerror = (event) => {
      setError(event.error === 'no-speech'
        ? 'Ses algılanamadı'
        : 'Ses tanıma hatası');
      setIsListening(false);
    };

    recognitionRef.current = recognition;
    setIsSupported(true);
  }, [language]);

  const startListening = () => {
    setError(null);
    setTranscript('');
    setIsListening(true);
    recognitionRef.current?.start();
  };

  const stopListening = () => {
    recognitionRef.current?.stop();
    setIsListening(false);
  };

  return { isListening, transcript, isSupported, error, startListening, stopListening };
}
```

**src/hooks/useFileUpload.ts:**
Firebase Storage upload per research:

```typescript
export function useFileUpload() {
  const [uploadState, setUploadState] = useState<{
    progress: number;
    status: 'idle' | 'uploading' | 'success' | 'error';
    url?: string;
    error?: string;
  }>({ progress: 0, status: 'idle' });

  const uploadFile = async (file: File, userId: string, folder: string) => {
    const maxSize = 5 * 1024 * 1024; // 5MB
    if (file.size > maxSize) {
      setUploadState({
        progress: 0,
        status: 'error',
        error: 'Dosya çok büyük (max 5MB)'
      });
      return null;
    }

    const fileName = `${Date.now()}-${file.name}`;
    const storageRef = ref(storage, `${userId}/${folder}/${fileName}`);
    const uploadTask = uploadBytesResumable(storageRef, file);

    setUploadState({ progress: 0, status: 'uploading' });

    return new Promise<string>((resolve, reject) => {
      uploadTask.on('state_changed',
        (snapshot) => {
          const progress = (snapshot.bytesTransferred / snapshot.totalBytes) * 100;
          setUploadState({ progress, status: 'uploading' });
        },
        (error) => {
          setUploadState({ progress: 0, status: 'error', error: 'Yükleme başarısız' });
          reject(error);
        },
        async () => {
          const url = await getDownloadURL(uploadTask.snapshot.ref);
          setUploadState({ progress: 100, status: 'success', url });
          resolve(url);
        }
      );
    });
  };

  return { uploadFile, uploadState };
}
```

**src/components/chat/VoiceButton.tsx:**
```typescript
export function VoiceButton({ onTranscript }: { onTranscript: (text: string) => void }) {
  const { isListening, transcript, isSupported, error, startListening, stopListening } = useVoiceInput();

  useEffect(() => {
    if (transcript) {
      onTranscript(transcript);
    }
  }, [transcript, onTranscript]);

  if (!isSupported) {
    return null; // Hide button if not supported
  }

  return (
    <Button
      type="button"
      variant="ghost"
      size="icon"
      onClick={isListening ? stopListening : startListening}
      className={isListening ? 'text-red-500 animate-pulse' : ''}
      title={isListening ? 'Dinleniyor...' : 'Sesli komut'}
    >
      {isListening ? <MicOff className="h-5 w-5" /> : <Mic className="h-5 w-5" />}
    </Button>
  );
}
```

**src/components/chat/AttachmentButton.tsx:**
```typescript
export function AttachmentButton({
  onUpload
}: {
  onUpload: (url: string, filename: string) => void
}) {
  const { uploadFile, uploadState } = useFileUpload();
  const { user } = useAuth();
  const inputRef = useRef<HTMLInputElement>(null);

  const handleFileSelect = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file || !user) return;

    try {
      const url = await uploadFile(file, user.uid, 'chat-attachments');
      if (url) {
        onUpload(url, file.name);
      }
    } catch (err) {
      // Error handled by hook
    }
  };

  return (
    <>
      <Button
        type="button"
        variant="ghost"
        size="icon"
        onClick={() => inputRef.current?.click()}
        disabled={uploadState.status === 'uploading'}
        title="Dosya ekle"
      >
        {uploadState.status === 'uploading' ? (
          <span className="text-xs">{Math.round(uploadState.progress)}%</span>
        ) : (
          <Paperclip className="h-5 w-5" />
        )}
      </Button>
      <input
        ref={inputRef}
        type="file"
        accept="image/*,.pdf,.doc,.docx"
        className="hidden"
        onChange={handleFileSelect}
      />
    </>
  );
}
```

**src/components/chat/ChatInput.tsx:**
Integrate voice and attachment buttons:

```typescript
export function ChatInput({ onSend }: { onSend: (content: string, attachments?: string[]) => void }) {
  const [input, setInput] = useState('');
  const [attachments, setAttachments] = useState<string[]>([]);

  const handleVoiceTranscript = (text: string) => {
    setInput(prev => prev + text);
  };

  const handleUpload = (url: string, filename: string) => {
    setAttachments(prev => [...prev, url]);
    // Optionally show filename in input
  };

  const handleSend = () => {
    if (!input.trim() && attachments.length === 0) return;
    onSend(input, attachments.length > 0 ? attachments : undefined);
    setInput('');
    setAttachments([]);
  };

  return (
    <div className="border-t p-3">
      {/* Attachment previews if any */}
      {attachments.length > 0 && (
        <div className="flex gap-2 mb-2">
          {attachments.map((url, i) => (
            <img key={i} src={url} className="w-16 h-16 object-cover rounded" />
          ))}
        </div>
      )}
      <div className="flex items-center gap-2">
        <AttachmentButton onUpload={handleUpload} />
        <Textarea
          value={input}
          onChange={(e) => setInput(e.target.value)}
          placeholder="Mesaj yazın..."
          className="flex-1 min-h-[40px] max-h-[120px]"
          onKeyDown={(e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
              e.preventDefault();
              handleSend();
            }
          }}
        />
        <VoiceButton onTranscript={handleVoiceTranscript} />
        <Button onClick={handleSend} disabled={!input.trim() && attachments.length === 0}>
          <Send className="h-5 w-5" />
        </Button>
      </div>
    </div>
  );
}
```
  </action>
  <verify>
- Voice button appears (if browser supports)
- Click voice button, speak, transcript appears in input
- Attachment button opens file picker
- Select image, see upload progress, preview appears
- Send with attachment - message includes image
  </verify>
  <done>
- Voice input transcribes Turkish speech
- File attachments upload to Firebase Storage
- Both integrated into chat input
- Graceful degradation if voice not supported
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify Complete AI Interface</name>
  <what-built>
Complete AI chat interface with:
- Natural language property/customer management
- Intelligent matching with scores and explanations
- Voice input (Turkish)
- File attachments
- Conversation persistence
  </what-built>
  <how-to-verify>
**Start the dev server:** `npm run dev`

**1. Test Property Addition via Chat:**
- Open chat (click floating button)
- Type: "3+1 daire Ankara Çankaya 2M TL"
- Expected: AI shows parsed data, asks "Bu mülkü ekleyeyim mi?"
- Type: "evet"
- Expected: Property created, inline card shown
- Verify: Go to /properties, see new property

**2. Test Customer Addition:**
- Type: "Mehmet adında müşteri ekle"
- Expected: Customer created (just name)
- Type: "Bütçesi 1.5M-3M, Ankara'da daire arıyor"
- Expected: Preferences updated

**3. Test Natural Language Search:**
- Type: "Bodrum'da villa ara"
- Expected: Search results with inline cards (or "bulunamadı" if none)
- Type: "10-20M arası mülkler"
- Expected: Filtered results

**4. Test Status Update:**
- Type: "Çankaya daireyi satıldı yap"
- Expected: AI identifies property, confirms, updates status

**5. Test Matching:**
- Type: "Mehmet için mülk bul"
- Expected: Ranked list with scores (e.g., "Villa Bodrum (92%)")
- Expected: Natural language explanation for each match
- Click "Görüntüle" on a match - opens property detail
- Click "Beğendi" - feedback recorded

**6. Test Voice Input (Chrome/Edge only):**
- Click microphone button
- Speak: "Yeni mülk ekle"
- Expected: Text appears in input field

**7. Test File Attachment:**
- Click paperclip button
- Select an image
- Expected: Upload progress, then preview
- Send message with attachment
- Expected: Attachment included in message

**8. Test Conversation Persistence:**
- Send a few messages
- Refresh the page
- Open chat
- Expected: Previous conversation visible

**9. Test Navigation Persistence:**
- With chat open, navigate to /settings
- Expected: Chat stays open
- Navigate to /customers
- Expected: Chat still open with same messages

**Verify all success criteria are met.**
  </how-to-verify>
  <resume-signal>Type "approved" if all tests pass, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
After all tasks:
1. All 9 verification scenarios pass
2. No console errors
3. Performance acceptable (responses stream, not blocked)
4. Turkish text correct throughout
5. Matching explanations conversational
</verification>

<success_criteria>
- Add property via chat with "3+1 daire Ankara 2M" format (AIUI-01)
- Add customer via chat with natural language (AIUI-02)
- Search properties with "Bodrum'da villa ara" (AIUI-03)
- Update status with "satıldı yap" (AIUI-04)
- AI understands Turkish (AIUI-05)
- Context maintained across messages (AIUI-06)
- Request matches and see scored results (ESLE-01, ESLE-02, ESLE-03)
- Voice input works for Turkish (partial AIUI-05)
- File attachments upload and display
- Human verification passes
</success_criteria>

<output>
After completion, create `.planning/phases/02-ai-interface-matching/02-05-SUMMARY.md`
</output>

---
phase: 03-background-processing-scraping
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - functions/package.json
  - functions/src/scrapers/common.ts
  - functions/src/scrapers/sahibinden.ts
  - functions/src/scrapers/hepsiemlak.ts
  - functions/src/scrapers/emlakjet.ts
  - functions/src/jobs/propertyImporter.ts
  - functions/src/index.ts
  - src/lib/ai/command-handlers.ts
  - src/components/chat/ImportPropertyPreview.tsx
autonomous: true
requirements:
  - PORT-01
  - PORT-02
  - PORT-03
  - PORT-04

must_haves:
  truths:
    - "User can paste sahibinden.com URL in chat and see parsed property preview"
    - "User can paste hepsiemlak URL in chat and see parsed property preview"
    - "User can paste emlakjet URL in chat and see parsed property preview"
    - "System warns if similar property exists before import"
    - "Photos shown as previews, downloaded only after user confirms"
  artifacts:
    - path: "functions/src/scrapers/sahibinden.ts"
      provides: "Sahibinden.com property scraper"
      exports: ["scrapeSahibinden"]
    - path: "functions/src/scrapers/hepsiemlak.ts"
      provides: "Hepsiemlak property scraper"
      exports: ["scrapeHepsiemlak"]
    - path: "functions/src/scrapers/emlakjet.ts"
      provides: "Emlakjet property scraper"
      exports: ["scrapeEmlakjet"]
    - path: "functions/src/scrapers/common.ts"
      provides: "Shared retry logic, rate limiting, duplicate detection"
      exports: ["scrapeWithRetry", "findSimilarProperties"]
    - path: "functions/src/jobs/propertyImporter.ts"
      provides: "Task queue handler for import + photo download"
      contains: "onTaskDispatched"
    - path: "src/components/chat/ImportPropertyPreview.tsx"
      provides: "Preview card for imported property before save"
  key_links:
    - from: "src/lib/ai/command-handlers.ts"
      to: "functions/importPropertyFromUrl"
      via: "httpsCallable"
      pattern: "httpsCallable.*importPropertyFromUrl"
    - from: "functions/src/jobs/propertyImporter.ts"
      to: "functions/src/scrapers/*"
      via: "URL-based router"
      pattern: "scrapeSahibinden|scrapeHepsiemlak|scrapeEmlakjet"
---

<objective>
Build portal scraping infrastructure for Turkish real estate sites with AI chat integration.

Purpose: Allow users to import properties from sahibinden.com, hepsiemlak, and emlakjet by pasting URLs in the AI chat. Scrapers run in Cloud Functions with Playwright for JavaScript rendering. Preview shows parsed fields before saving, warns about duplicates.

Output: Three portal scrapers, import task queue, and chat-integrated preview/confirm flow.
</objective>

<execution_context>
@/home/cagr/.claude/get-shit-done/workflows/execute-plan.md
@/home/cagr/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-background-processing-scraping/03-RESEARCH.md
@.planning/phases/03-background-processing-scraping/03-CONTEXT.md
@.planning/phases/02-ai-interface-matching/02-03-SUMMARY.md
@src/lib/ai/command-handlers.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create scraper infrastructure with shared utilities</name>
  <files>
    functions/package.json
    functions/src/scrapers/common.ts
  </files>
  <action>
Add Playwright and create shared scraping utilities:

1. Update functions/package.json to add:
   - playwright (^1.48+) for web scraping
   - exponential-backoff (^3.x) for retry logic
   - fuzzball (^2.1.6+) for duplicate detection

2. Create functions/src/scrapers/common.ts:

   Interface ScrapedProperty:
   ```typescript
   interface ScrapedProperty {
     title: string;
     price: number;
     currency: 'TRY' | 'USD' | 'EUR';
     propertyType: 'daire' | 'villa' | 'arsa' | 'işyeri' | 'other';
     location: {
       city: string;
       district?: string;
       neighborhood?: string;
       fullAddress?: string;
     };
     area?: number;           // m2
     rooms?: string;          // "3+1", "stüdyo", etc.
     features?: string[];     // ["balkon", "otopark", etc.]
     description?: string;
     photoUrls: string[];     // Original URLs (not downloaded yet)
     sourceUrl: string;
     sourcePortal: 'sahibinden' | 'hepsiemlak' | 'emlakjet';
     sourceId?: string;       // Portal's listing ID
   }
   ```

   Function scrapeWithRetry<T>:
   - Generic wrapper using exponential-backoff
   - 3 attempts, starting delay 1000ms, max delay 10000ms
   - Per RESEARCH.md Pattern 5

   Function detectPortal(url: string):
   - Returns 'sahibinden' | 'hepsiemlak' | 'emlakjet' | 'unknown'
   - Check hostname contains portal name

   Function findSimilarProperties(scraped: ScrapedProperty, userId: string):
   - Use fuzzball for fuzzy matching (per RESEARCH.md Pattern 7)
   - Compare title + address + location
   - 75% similarity threshold
   - Return matching properties array

   Function createBrowser():
   - Launch Playwright chromium in headless mode
   - Set realistic user agent
   - Return browser and page

   Anti-bot measures:
   - Random delay 2-4 seconds between requests
   - Realistic viewport (1920x1080)
   - User-Agent: Mozilla/5.0 Chrome...
  </action>
  <verify>
    - common.ts compiles without errors
    - ScrapedProperty interface defined
    - scrapeWithRetry uses exponential-backoff
    - findSimilarProperties uses fuzzball
  </verify>
  <done>Shared scraper utilities ready with retry logic and duplicate detection</done>
</task>

<task type="auto">
  <name>Task 2: Create portal scrapers for sahibinden, hepsiemlak, emlakjet</name>
  <files>
    functions/src/scrapers/sahibinden.ts
    functions/src/scrapers/hepsiemlak.ts
    functions/src/scrapers/emlakjet.ts
  </files>
  <action>
Create scrapers for each Turkish real estate portal:

1. Create functions/src/scrapers/sahibinden.ts:
   - Export async function scrapeSahibinden(url: string): Promise<ScrapedProperty>

   Sahibinden.com DOM selectors (may need adjustment if site changes):
   - Title: h1.classifiedDetailTitle or similar
   - Price: .classifiedPrice or span with price class
   - Location: breadcrumb items or location info section
   - Area: "m2" field in detail table
   - Rooms: "oda sayısı" field in detail table
   - Photos: gallery images (get src URLs)
   - Description: .classifiedDescription or detail text

   Extract and normalize:
   - Parse price to number (remove "TL", thousand separators)
   - Extract rooms format (3+1, etc.)
   - Map property type from category
   - Get all photo URLs (don't download, just URLs)

2. Create functions/src/scrapers/hepsiemlak.ts:
   - Export async function scrapeHepsiemlak(url: string): Promise<ScrapedProperty>

   Hepsiemlak selectors:
   - Title: h1.detail-title or similar
   - Price: .detail-price or price element
   - Location: location breadcrumb or address field
   - Details: property info section
   - Photos: gallery carousel images

3. Create functions/src/scrapers/emlakjet.ts:
   - Export async function scrapeEmlakjet(url: string): Promise<ScrapedProperty>

   Emlakjet selectors:
   - Title: h1 in detail page
   - Price: price element
   - Location: location/address section
   - Details: property specs
   - Photos: photo gallery

Each scraper:
- Use scrapeWithRetry wrapper for resilience
- Create browser, navigate to URL, wait for networkidle
- Extract all fields
- Close browser in finally block
- Return ScrapedProperty or throw with descriptive error

Note: Selectors are best-effort based on typical patterns. May need adjustment during testing. Include error handling for missing elements.

Per user decision from CONTEXT.md:
- Only scrape public listing pages
- Respect rate limits (delays between requests)
  </action>
  <verify>
    - All three scrapers compile
    - Each exports correctly typed function
    - Playwright usage matches research patterns
    - Error handling in place
  </verify>
  <done>Portal scrapers ready for sahibinden, hepsiemlak, emlakjet</done>
</task>

<task type="auto">
  <name>Task 3: Create import task queue and chat integration</name>
  <files>
    functions/src/jobs/propertyImporter.ts
    functions/src/index.ts
    src/lib/ai/command-handlers.ts
    src/components/chat/ImportPropertyPreview.tsx
    src/lib/ai/structured-schemas.ts
  </files>
  <action>
Create the import flow from chat URL paste to property creation:

1. Create functions/src/jobs/propertyImporter.ts:

   Callable function importPropertyFromUrl (onCall):
   - Input: { url: string, userId: string }
   - Output: { scraped: ScrapedProperty, similar: Property[] }

   Logic:
   - Detect portal from URL
   - Call appropriate scraper
   - Find similar properties with fuzzball
   - Return scraped data + similar properties (for duplicate warning)
   - Do NOT save yet - just return for preview

   Task function processPropertyImport (onTaskDispatched):
   - Input: { scraped: ScrapedProperty, userId: string, photoDownload: boolean }
   - Triggered after user confirms import

   Logic:
   - Create property document in Firestore
   - If photoDownload true:
     - Download each photoUrl
     - Upload to Firebase Storage
     - Update property with local photo URLs
   - Return created property ID

   Per user decision: "Photos: Show linked previews first, download and store only after user confirms import"

2. Update functions/src/index.ts:
   - Export importPropertyFromUrl and processPropertyImport

3. Update src/lib/ai/structured-schemas.ts:
   - Add import_property intent type
   - Schema: { intent: 'import_property', url: string }

4. Update src/lib/ai/command-handlers.ts:
   - Add handler for import_property intent
   - Detect URL in user message (regex for portal domains)
   - Call importPropertyFromUrl via httpsCallable
   - Return scraped preview with embeddedContent: 'import_preview'
   - If similar properties exist, include warning message

   Confirmation flow (per existing confirmation-first pattern):
   - First message: Show preview + similar warning if any
   - Ask "İçe aktarılsın mı?" or "Mevcut güncellensin mi?" if similar
   - On confirm: Trigger processPropertyImport task

5. Create src/components/chat/ImportPropertyPreview.tsx:
   - Props: { scraped: ScrapedProperty, similar?: Property[] }

   Display:
   - Property title, location, price
   - Photo thumbnails (using original URLs - lazy loaded)
   - Key details: area, rooms, type
   - If similar exists: Warning card "Benzer ilan bulundu" with property link

   Per user decision: "Show preview of parsed fields, user confirms before saving"

   Actions:
   - "İçe Aktar" button → confirm import
   - "Güncelle" button (if similar) → update existing
   - "İptal" → cancel
  </action>
  <verify>
    - functions build with new exports
    - command-handlers detects portal URLs
    - ImportPropertyPreview renders scraped data
    - npm run build succeeds in root
  </verify>
  <done>Portal import flow complete with preview, duplicate warning, and confirmation</done>
</task>

</tasks>

<verification>
1. `npm run build` succeeds (client + functions TypeScript check)
2. All three scrapers export typed functions
3. importPropertyFromUrl callable returns scraped data
4. Similar properties detected with fuzzball
5. ImportPropertyPreview shows parsed fields
6. Confirmation flow follows existing pattern
7. All Turkish text in UI
</verification>

<success_criteria>
- User pastes sahibinden.com URL in chat
- AI recognizes URL, calls scraper
- Preview shows parsed property details
- Photo URLs displayed (not downloaded yet)
- If similar property exists, warning shown
- User confirms, property saved to Firestore
- Photos downloaded to Storage on confirm
- Same flow works for hepsiemlak and emlakjet
</success_criteria>

<output>
After completion, create `.planning/phases/03-background-processing-scraping/03-03-SUMMARY.md`
</output>
